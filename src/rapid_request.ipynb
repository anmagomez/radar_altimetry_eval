{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0dfb14-4cb1-4e57-9398-78f352822ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ground_data import GroundObservations\n",
    "from LOCSS_data_structure import GaugeCollection\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1308902f-3177-4125-81b4-591d8d83fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate each lake in a folder\n",
    "go=GroundObservations()\n",
    "df_locss_podaac=go.get_locss('LOCSS', all_fds=True)\n",
    "\n",
    "g_path='../data/locss_2_podaac/by_st'\n",
    "f_exist=os.path.exists(g_path)\n",
    "stations=df_locss_podaac['gauge_id'].unique()\n",
    "df_locss_podaac.rename(columns={'name_x':'name_at_measurement', 'notes_x':'reading_notes', 'name_y':'lake_name',\n",
    "                                       'notes_y':'installation_notes'}, inplace=True)\n",
    "st_fields=['gauge_id','lake_name','date','height','is_bubble_level_okay','installation_notes', 'city','latitude','longitude','timezone',\n",
    "           'unit','min_height','max_height','installation_date','initial_reading','reading_notes', 'updated_at']\n",
    "df_locss_podaac=df_locss_podaac[st_fields].copy()\n",
    "if not f_exist:\n",
    "    os.makedirs(g_path)\n",
    "for st in stations:\n",
    "    st_path=g_path+'/'+st\n",
    "    f_st_exist=os.path.exists(st_path)\n",
    "    if not f_st_exist:\n",
    "        os.makedirs(st_path)\n",
    "    df=df_locss_podaac.loc[df_locss_podaac['gauge_id']==st]\n",
    "    df.to_csv(st_path+'/LOCSS_'+st+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c12b695e-fef6-4cbf-88ff-4faa79c2187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gauge_id', 'lake_name', 'date', 'height', 'is_bubble_level_okay',\n",
       "       'installation_notes', 'city', 'latitude', 'longitude', 'timezone',\n",
       "       'unit', 'min_height', 'max_height', 'installation_date',\n",
       "       'initial_reading', 'reading_notes', 'updated_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locss_podaac.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afec2c26-8982-41c0-b4ad-c54b27377e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read with no merge for po.daac\n",
    "dt_fields=['gauge_id','name_x','date','height','is_bubble_level_okay','notes_x']\n",
    "st_fields=['gauge_id','name','city','latitude','longitude','timezone','unit','min_height','max_height','installation_date','initial_reading','notes', 'updated_at']\n",
    "\n",
    "dir_ts='../data/readings_up_to_20220404.csv'\n",
    "dir_loc='../data/gauges_up_to_20220404.csv'\n",
    "id_fd='gauge_id'\n",
    "date_fd='date'\n",
    "time_fd='time'\n",
    "height_fd='height'\n",
    "df_locss=pd.read_csv(dir_ts)\n",
    "df_coord_locss=pd.read_csv(dir_loc, sep=\",\")\n",
    "gc=GaugeCollection()\n",
    "\n",
    "df_locss_filtered=gc.filter_test_gages(df_locss,id_fd).copy()\n",
    "df_locss_filtered=pd.merge(df_locss_filtered, df_coord_locss, on=id_fd)\n",
    "df_locss_filtered=df_locss_filtered.loc[(df_locss_filtered[height_fd]>=df_locss_filtered['min_height'])&\n",
    "                                        (df_locss_filtered[height_fd]<=df_locss_filtered['max_height'])].copy()\n",
    "df_locss_filtered[date_fd]=pd.to_datetime((df_locss_filtered[date_fd].astype(str)+' '+df_locss_filtered[time_fd].astype(str)), \n",
    "                                                  format='%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4da64b3-2cf0-4872-8a36-37a0c316f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locss_filtered=df_locss_filtered[dt_fields]\n",
    "df_locss_filtered.rename(columns={'name_x':'name', 'notes_x':'notes'}, inplace=True)\n",
    "df_coord_locss=df_coord_locss[st_fields]\n",
    "out_path='../data/locss_2_podaac/st_rd/'\n",
    "f_exist=os.path.exists(out_path)\n",
    "if not f_exist:\n",
    "    os.makedirs(out_path)\n",
    "df_locss_filtered.to_csv(out_path+'locss_readings_up_to_20220404.csv', index=False)\n",
    "df_coord_locss.to_csv(out_path+'locss_gauges_up_to_20220404.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c55f33b-dfb7-400c-aca9-2aa829deb179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br_19069_MACHADINHO.xlsx\n",
      "br_19126_XINGO.xlsx\n",
      "br_19060_SEGREDO.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Test getting brasilian ts\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def _get_all_lakes(file_list, by=None):\n",
    "    df=pd.DataFrame(file_list, columns=['file_name'])\n",
    "    df_ex=df['file_name'].str.split('_', expand=True)\n",
    "    \n",
    "    df_ex=df_ex.rename(columns={0:'location',1:'lake_id',2:'name'})\n",
    "    df_ex['name']=df_ex['name'].apply(lambda x:x[:-4])\n",
    "    df_all=pd.concat((df,df_ex), axis=1)\n",
    "    if by=='lake_id':\n",
    "        return df_all['lake_id']\n",
    "    elif by=='name':\n",
    "        return df_all['name']\n",
    "    else:\n",
    "        return df_all\n",
    "postfix='.xlsx'\n",
    "path='../data/brasil/'\n",
    "files = [f for f in os.listdir(path) if (os.path.isfile(os.path.join(path, f))&\n",
    "                                                  (f.endswith(postfix)))]\n",
    "files\n",
    "start_st=3\n",
    "end_st=8\n",
    "st=[f[start_st:end_st] for f in files]\n",
    "for s in st:\n",
    "    print(files[st.index(s)])\n",
    "    \n",
    "# type(get_all_lakes(data, by='lake_id'))\n",
    "# type(get_all_lakes(data, by=None))\n",
    "# type(get_all_lakes(data, by='name'))\n",
    "# _get_all_lakes(files, by='lake_id')\n",
    "# df=_get_all_lakes(files, by=None)\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     print(row['file_name'])\n",
    "#     df=pd.read_excel(path+row['file_name'])\n",
    "#     break\n",
    "# # [f[] for f in files] \n",
    "# df\n",
    "# f[:-len(postfix)][-length_id:]\n",
    "# _get_all_lakes(files, by='name')\n",
    "# df_coord['lon_tx'].astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed26ff2-7b91-4bd2-a67d-6e45293b285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test what is faster \n",
    "\n",
    "import xlrd\n",
    "import timeit\n",
    "\n",
    "path='/home/angelica/Documents/py_linux/pylocss/data/brasil/br_19126_XINGO.ods'\n",
    "# xlrd.open_workbook(filename=path)\n",
    "%timeit pd.read_excel(path, engine='odf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df158ec-3eb3-492e-8732-5013242e7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/angelica/Documents/py_linux/pylocss/data/brasil/br_19126_XINGO.xlsx'\n",
    "# xlrd.open_workbook(filename=path)\n",
    "%timeit pd.read_excel(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
