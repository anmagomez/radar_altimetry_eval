{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0dfb14-4cb1-4e57-9398-78f352822ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ground_data import GroundObservations\n",
    "from LOCSS_data_structure import GaugeCollection\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1308902f-3177-4125-81b4-591d8d83fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate each lake in a folder\n",
    "go=GroundObservations()\n",
    "df_locss_podaac=go.get_locss('LOCSS', all_fds=True)\n",
    "\n",
    "g_path='../data/locss_2_podaac/by_st'\n",
    "f_exist=os.path.exists(g_path)\n",
    "stations=df_locss_podaac['gauge_id'].unique()\n",
    "df_locss_podaac.rename(columns={'name_x':'name_at_measurement', 'notes_x':'reading_notes', 'name_y':'lake_name',\n",
    "                                       'notes_y':'installation_notes'}, inplace=True)\n",
    "st_fields=['gauge_id','lake_name','date','height','is_bubble_level_okay','installation_notes', 'city','latitude','longitude','timezone',\n",
    "           'unit','min_height','max_height','installation_date','initial_reading','reading_notes', 'updated_at']\n",
    "df_locss_podaac=df_locss_podaac[st_fields].copy()\n",
    "if not f_exist:\n",
    "    os.makedirs(g_path)\n",
    "for st in stations:\n",
    "    st_path=g_path+'/'+st\n",
    "    f_st_exist=os.path.exists(st_path)\n",
    "    if not f_st_exist:\n",
    "        os.makedirs(st_path)\n",
    "    df=df_locss_podaac.loc[df_locss_podaac['gauge_id']==st]\n",
    "    df.to_csv(st_path+'/LOCSS_'+st+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c12b695e-fef6-4cbf-88ff-4faa79c2187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gauge_id', 'lake_name', 'date', 'height', 'is_bubble_level_okay',\n",
       "       'installation_notes', 'city', 'latitude', 'longitude', 'timezone',\n",
       "       'unit', 'min_height', 'max_height', 'installation_date',\n",
       "       'initial_reading', 'reading_notes', 'updated_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locss_podaac.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afec2c26-8982-41c0-b4ad-c54b27377e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read with no merge for po.daac\n",
    "dt_fields=['gauge_id','name_x','date','height','is_bubble_level_okay','notes_x']\n",
    "st_fields=['gauge_id','name','city','latitude','longitude','timezone','unit','min_height','max_height','installation_date','initial_reading','notes', 'updated_at']\n",
    "\n",
    "dir_ts='../data/readings_up_to_20220404.csv'\n",
    "dir_loc='../data/gauges_up_to_20220404.csv'\n",
    "id_fd='gauge_id'\n",
    "date_fd='date'\n",
    "time_fd='time'\n",
    "height_fd='height'\n",
    "df_locss=pd.read_csv(dir_ts)\n",
    "df_coord_locss=pd.read_csv(dir_loc, sep=\",\")\n",
    "gc=GaugeCollection()\n",
    "\n",
    "df_locss_filtered=gc.filter_test_gages(df_locss,id_fd).copy()\n",
    "df_locss_filtered=pd.merge(df_locss_filtered, df_coord_locss, on=id_fd)\n",
    "df_locss_filtered=df_locss_filtered.loc[(df_locss_filtered[height_fd]>=df_locss_filtered['min_height'])&\n",
    "                                        (df_locss_filtered[height_fd]<=df_locss_filtered['max_height'])].copy()\n",
    "df_locss_filtered[date_fd]=pd.to_datetime((df_locss_filtered[date_fd].astype(str)+' '+df_locss_filtered[time_fd].astype(str)), \n",
    "                                                  format='%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4da64b3-2cf0-4872-8a36-37a0c316f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locss_filtered=df_locss_filtered[dt_fields]\n",
    "df_locss_filtered.rename(columns={'name_x':'name', 'notes_x':'notes'}, inplace=True)\n",
    "df_coord_locss=df_coord_locss[st_fields]\n",
    "out_path='../data/locss_2_podaac/st_rd/'\n",
    "f_exist=os.path.exists(out_path)\n",
    "if not f_exist:\n",
    "    os.makedirs(out_path)\n",
    "df_locss_filtered.to_csv(out_path+'locss_readings_up_to_20220404.csv', index=False)\n",
    "df_coord_locss.to_csv(out_path+'locss_gauges_up_to_20220404.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c55f33b-dfb7-400c-aca9-2aa829deb179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br_19069_MACHADINHO.xlsx\n",
      "br_19126_XINGO.xlsx\n",
      "br_19060_SEGREDO.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Test getting brasilian ts\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def _get_all_lakes(file_list, by=None):\n",
    "    df=pd.DataFrame(file_list, columns=['file_name'])\n",
    "    df_ex=df['file_name'].str.split('_', expand=True)\n",
    "    \n",
    "    df_ex=df_ex.rename(columns={0:'location',1:'lake_id',2:'name'})\n",
    "    df_ex['name']=df_ex['name'].apply(lambda x:x[:-4])\n",
    "    df_all=pd.concat((df,df_ex), axis=1)\n",
    "    if by=='lake_id':\n",
    "        return df_all['lake_id']\n",
    "    elif by=='name':\n",
    "        return df_all['name']\n",
    "    else:\n",
    "        return df_all\n",
    "postfix='.xlsx'\n",
    "path='../data/brasil/'\n",
    "files = [f for f in os.listdir(path) if (os.path.isfile(os.path.join(path, f))&\n",
    "                                                  (f.endswith(postfix)))]\n",
    "files\n",
    "start_st=3\n",
    "end_st=8\n",
    "st=[f[start_st:end_st] for f in files]\n",
    "for s in st:\n",
    "    print(files[st.index(s)])\n",
    "    \n",
    "# type(get_all_lakes(data, by='lake_id'))\n",
    "# type(get_all_lakes(data, by=None))\n",
    "# type(get_all_lakes(data, by='name'))\n",
    "# _get_all_lakes(files, by='lake_id')\n",
    "# df=_get_all_lakes(files, by=None)\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     print(row['file_name'])\n",
    "#     df=pd.read_excel(path+row['file_name'])\n",
    "#     break\n",
    "# # [f[] for f in files] \n",
    "# df\n",
    "# f[:-len(postfix)][-length_id:]\n",
    "# _get_all_lakes(files, by='name')\n",
    "# df_coord['lon_tx'].astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed26ff2-7b91-4bd2-a67d-6e45293b285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test what is faster \n",
    "\n",
    "import xlrd\n",
    "import timeit\n",
    "\n",
    "path='/home/angelica/Documents/py_linux/pylocss/data/brasil/br_19126_XINGO.ods'\n",
    "# xlrd.open_workbook(filename=path)\n",
    "%timeit pd.read_excel(path, engine='odf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df158ec-3eb3-492e-8732-5013242e7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/angelica/Documents/py_linux/pylocss/data/brasil/br_19126_XINGO.xlsx'\n",
    "# xlrd.open_workbook(filename=path)\n",
    "%timeit pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ba70240-ab67-468a-803c-c1dfefcefd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts_preprocesing import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd7a9ddb-4d90-44b7-b74f-3387cb44da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([639.41776294, 638.79814716, 639.03307506, 639.08598951,\n",
       "       638.9512785 , 639.22153111, 639.86431209, 639.76201283,\n",
       "       639.94931077, 639.9821185 , 639.57211619, 639.297528  ,\n",
       "       639.25073062, 639.17055127, 639.08187817, 639.40142945,\n",
       "       639.39348567, 639.89583095, 639.7917532 , 640.25812196,\n",
       "       640.10360696, 640.42202405, 640.42524257, 640.13159718,\n",
       "       639.72194669, 639.1764573 , 639.00231116, 639.25268834,\n",
       "       639.51002587, 639.60377963, 639.87170993, 640.49675565,\n",
       "       640.03452703, 639.76819589, 640.20760798, 640.47443189,\n",
       "       640.08513394, 639.50381148, 639.14197758, 638.95128786,\n",
       "       639.06035578, 639.00788169, 639.46582925, 639.97037448,\n",
       "       639.85536325, 640.67367134, 640.45245077, 640.07032121,\n",
       "       640.21899268, 640.52368635, 639.96197048, 640.11167615,\n",
       "       639.65527678, 639.47112128, 639.53081034, 639.4678867 ,\n",
       "       640.09827893, 640.31512617, 640.54360892, 640.50777014,\n",
       "       640.37066558, 640.49162851, 640.7388485 , 640.60679998,\n",
       "       640.27838157, 639.82724902, 639.76274026, 639.37566248,\n",
       "       639.46930562, 639.45185403, 640.63036677, 639.89885315,\n",
       "       639.51374579, 640.14552382, 640.34267779, 640.48893219,\n",
       "       640.34222055])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test new function load altis with changes \n",
    "g_path='/home/angelica/Dropbox/apps/python_pychm/locss/data/alti_timeseries/'\n",
    "altis_name='AlTiS_TimeSeries_Jason-3_GDR-F_0215_S4017'\n",
    "altis_name='AlTiS_TimeSeries_Sentinel-3A_0749_S4016'\n",
    "altis_date_fd = 'date'  # Same value for Sentinel-3A/B\n",
    "altis_height_fd = 'ice1_ku_SurfHeight_alti_median'  # Same value for Sentinel-3A/B\n",
    "nodataalti=-9999\n",
    "wse_ref='g'\n",
    "(altiyear, altimonth, altiday, altihour, altiminute, altiwelev)=load_altis(g_path+altis_name+'.csv', \n",
    "                                                                               altis_date_fd, altis_height_fd, nodataalti=-9999, wse_ref=wse_ref)\n",
    "\n",
    "altiwelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d292cda-723d-4ffe-889a-f33eaa9011d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([663.07981069, 662.47482143, 662.70496378, 662.74140667,\n",
       "       662.61090978, 662.86109502, 663.50252798, 663.39862791,\n",
       "       663.5459598 , 663.63459361, 663.22171309, 662.94419173,\n",
       "       662.90517984, 662.82497422, 662.71601449, 663.08318062,\n",
       "       663.0269616 , 663.57564589, 663.43465858, 663.93466536,\n",
       "       663.75011991, 664.06734304, 664.06818937, 663.76005322,\n",
       "       663.35692908, 662.83904057, 662.65802611, 662.89198135,\n",
       "       663.16243485, 663.24401847, 663.51795276, 664.16366049,\n",
       "       663.7086631 , 663.43072491, 663.87263624, 664.13096986,\n",
       "       663.74833067, 663.14252579, 662.7969605 , 662.60973331,\n",
       "       662.70915986, 662.64661454, 663.1199493 , 663.60987749,\n",
       "       663.51366899, 664.33485192, 664.10550297, 663.71663475,\n",
       "       663.86306733, 664.15908874, 663.61175306, 663.31361751,\n",
       "       662.86337152, 662.66698005, 662.73149651, 662.6737999 ,\n",
       "       663.30699027, 663.51799969, 663.74929344, 663.69564737,\n",
       "       663.58061859, 663.69830568, 663.94073831, 663.81093435,\n",
       "       663.48989601, 663.02244619, 662.95260894, 662.58116377,\n",
       "       662.66479349, 662.64542774, 663.82868625, 663.09626507,\n",
       "       662.70583711, 663.3453031 , 663.55235396, 663.68549496,\n",
       "       663.54622245])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test new function load altis with changes \n",
    "g_path='/home/angelica/Dropbox/apps/python_pychm/locss/data/alti_timeseries/'\n",
    "altis_name='AlTiS_TimeSeries_Sentinel-3A_0749_S4016'\n",
    "altis_date_fd = 'date'  # Same value for Sentinel-3A/B\n",
    "altis_height_fd = 'ice1_ku_SurfHeight_alti_median'  # Same value for Sentinel-3A/B\n",
    "nodataalti=-9999\n",
    "wse_ref='e'\n",
    "ncolgeoid='geoid_01_median'\n",
    "(altiyear1, altimonth, altiday, altihour, altiminute, altiwelev1)=load_altis(g_path+altis_name+'.csv', \n",
    "                                                                            altis_date_fd, altis_height_fd, ncolgeoid=ncolgeoid,\n",
    "                                                                            nodataalti=-9999, wse_ref=wse_ref)\n",
    "\n",
    "altiwelev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "83d918d7-845f-4492-86b6-6d7e6047ced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get ellipsoide\n",
      "get ellipsoide\n",
      "get geoide\n"
     ]
    }
   ],
   "source": [
    "#Making the correction from whole code\n",
    "\n",
    "text=['AlTiS_TimeSeries_Sentinel-3A_0562_S4128', 'AlTiS_TimeSeries_Sentinel-3B_0026_N4814', 'AlTiS_TimeSeries_Jason-3_GDR-F_0215_S4017']\n",
    "s=[f.find('Sentinel-3') for f in text]\n",
    "for v in s:\n",
    "    if v!=-1:\n",
    "        print('get ellipsoide')\n",
    "    else:\n",
    "        print('get geoide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42a29a56-0a6b-4397-8262-55c70c363b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_period(df_ts1, df_ts2, date_ts1_fd, date_ts2_fd, delta_days=False, ndays=0):\n",
    "    '''Get the common period of time between two time series, df_ts1 and df_ts2\n",
    "        WARNING: If not timezone information in any of the dataframe, utc is assumed \n",
    "        It can return the common period + or - a number of days based on df_ts1\n",
    "        Assume both dataframe datetime is utc\n",
    "        If delta_days=False, ndays is assume =0, returns a common dataframe with the interception between the two dataframes\n",
    "        If delta_days=True, ndays has to be different from 0\n",
    "            Rules:\n",
    "                if df_ts1 starts earlier than df_ts2, common period starts at initial time of df_ts2\n",
    "                if df_ts1 starts later than df_ts2, common period starts ndays earlier than initial time of df_ts1\n",
    "                if df_ts1 ends earlier than df_ts2, common period ends ndays later than final time of df_ts1\n",
    "                if df_ts1 ends later than df_ts2, common period end at the final time of df_ts2\n",
    "    '''\n",
    "    \n",
    "    if delta_days==True and ndays<=0:\n",
    "        #TODO:Convert this to raise exceptions\n",
    "        print('Error ndays cannot be 0 or lower if delta_days=True')\n",
    "        return None\n",
    "    if delta_days==False:\n",
    "        ndays=0\n",
    "    \n",
    "    utc=pytz.utc\n",
    "    \n",
    "    #Min and max dates in df_ts1 and df_ts2\n",
    "    if df_ts1[date_ts1_fd].dt.tz is None:\n",
    "        df_ts1[date_ts1_fd]=[utc.localize(date) for date in df_ts1[date_ts1_fd]]\n",
    "        \n",
    "    if df_ts2[date_ts2_fd].dt.tz is None:\n",
    "        df_ts2[date_ts2_fd]=[utc.localize(date) for date in df_ts2[date_ts2_fd]]\n",
    "        \n",
    "    earlier_date_ts1=min(df_ts1[date_ts1_fd])\n",
    "    final_date_ts1=max(df_ts1[date_ts1_fd])\n",
    "        \n",
    "    earlier_date_ts2=min(df_ts2[date_ts2_fd])\n",
    "    final_date_ts2=max(df_ts2[date_ts2_fd])\n",
    "\n",
    "    if earlier_date_ts1 >= earlier_date_ts2:\n",
    "        initial_date=earlier_date_ts1 - dt.timedelta(days=ndays)\n",
    "    else:\n",
    "        initial_date=earlier_date_ts2\n",
    "\n",
    "    if final_date_ts1 >= final_date_ts2:\n",
    "        end_date=final_date_ts2\n",
    "    else:\n",
    "        end_date=final_date_ts1 + dt.timedelta(days=ndays)\n",
    "    \n",
    "    #filter dataframes\n",
    "    df_ts1=df_ts1.loc[(df_ts1[date_ts1_fd]>=initial_date)&(df_ts1[date_ts1_fd]<=end_date)].copy()\n",
    "    df_ts2=df_ts2.loc[(df_ts2[date_ts2_fd]>=initial_date)&(df_ts2[date_ts2_fd]<=end_date)].copy()\n",
    "    \n",
    "    return (df_ts1, df_ts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9e69f566-845c-45f3-9dcf-8c79ba753941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "from datetime import datetime, timezone\n",
    "import datetime as dt\n",
    "\n",
    "s_dict={'date': ['2001-12-20','2002-01-05','2002-01-15','2002-02-04','2002-02-09'], 'val':[1.5,2,2.4,3,2]}\n",
    "g_dict={'date': ['2002-01-01','2002-01-02','2002-01-03',\n",
    "                 '2002-01-04','2002-01-05','2002-01-06',\n",
    "                '2002-01-08','2002-01-10','2002-01-14',\n",
    "                '2002-01-15','2002-01-18','2002-01-20',\n",
    "                '2002-01-21','2002-02-07','2002-02-08'], 'val':[1.5,2,1,\n",
    "                                                                2,2.4,3,\n",
    "                                                               2,2.1,2.2,\n",
    "                                                               2,1,1,\n",
    "                                                               2,2.5,1]}\n",
    "df_s=pd.DataFrame(s_dict)\n",
    "df_s['date']=pd.to_datetime(df_s['date'], utc=True)\n",
    "\n",
    "df_g=pd.DataFrame(g_dict)\n",
    "df_g['date']=pd.to_datetime(df_g['date'])#, utc=True)\n",
    "df_g['date'].dt.tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "be25d130-cd96-47a3-b4ce-b2d93ba665c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-12-20 00:00:00+00:00</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-05 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-15 00:00:00+00:00</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-02-04 00:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-02-09 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  val\n",
       "0 2001-12-20 00:00:00+00:00  1.5\n",
       "1 2002-01-05 00:00:00+00:00  2.0\n",
       "2 2002-01-15 00:00:00+00:00  2.4\n",
       "3 2002-02-04 00:00:00+00:00  3.0\n",
       "4 2002-02-09 00:00:00+00:00  2.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "826dd620-734a-47b9-9e61-87cb2c41af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-02</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-04</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-05</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002-01-06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-01-08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002-01-10</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-01-14</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002-01-15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2002-01-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002-01-20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002-01-21</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002-02-07</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002-02-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  val\n",
       "0  2002-01-01  1.5\n",
       "1  2002-01-02  2.0\n",
       "2  2002-01-03  1.0\n",
       "3  2002-01-04  2.0\n",
       "4  2002-01-05  2.4\n",
       "5  2002-01-06  3.0\n",
       "6  2002-01-08  2.0\n",
       "7  2002-01-10  2.1\n",
       "8  2002-01-14  2.2\n",
       "9  2002-01-15  2.0\n",
       "10 2002-01-18  1.0\n",
       "11 2002-01-20  1.0\n",
       "12 2002-01-21  2.0\n",
       "13 2002-02-07  2.5\n",
       "14 2002-02-08  1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5ec82e33-d2c1-43a9-8e98-9e00cf65d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sx, df_gx=get_common_period(df_ts1=df_s, df_ts2=df_g, date_ts1_fd='date', date_ts2_fd='date', delta_days=True, ndays=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bae5c560-036a-47f8-a933-cbe9b78ce4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-05 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-15 00:00:00+00:00</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-02-04 00:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  val\n",
       "1 2002-01-05 00:00:00+00:00  2.0\n",
       "2 2002-01-15 00:00:00+00:00  2.4\n",
       "3 2002-02-04 00:00:00+00:00  3.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae089c96-bc9d-46e4-b02c-c2599f8a123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-01 00:00:00+00:00</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-02 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-03 00:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-04 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-05 00:00:00+00:00</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002-01-06 00:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-01-08 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002-01-10 00:00:00+00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-01-14 00:00:00+00:00</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002-01-15 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2002-01-18 00:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002-01-20 00:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002-01-21 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002-02-07 00:00:00+00:00</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002-02-08 00:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  val\n",
       "0  2002-01-01 00:00:00+00:00  1.5\n",
       "1  2002-01-02 00:00:00+00:00  2.0\n",
       "2  2002-01-03 00:00:00+00:00  1.0\n",
       "3  2002-01-04 00:00:00+00:00  2.0\n",
       "4  2002-01-05 00:00:00+00:00  2.4\n",
       "5  2002-01-06 00:00:00+00:00  3.0\n",
       "6  2002-01-08 00:00:00+00:00  2.0\n",
       "7  2002-01-10 00:00:00+00:00  2.1\n",
       "8  2002-01-14 00:00:00+00:00  2.2\n",
       "9  2002-01-15 00:00:00+00:00  2.0\n",
       "10 2002-01-18 00:00:00+00:00  1.0\n",
       "11 2002-01-20 00:00:00+00:00  1.0\n",
       "12 2002-01-21 00:00:00+00:00  2.0\n",
       "13 2002-02-07 00:00:00+00:00  2.5\n",
       "14 2002-02-08 00:00:00+00:00  1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "81e131e0-d70c-4c58-8240-41fe00a3fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val</th>\n",
       "      <th>median_d_2</th>\n",
       "      <th>mean_d_2</th>\n",
       "      <th>count_d_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-12-20 00:00:00+00:00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-05 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-15 00:00:00+00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-02-04 00:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-02-09 00:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  val  median_d_2  mean_d_2  count_d_2\n",
       "0 2001-12-20 00:00:00+00:00  1.5         NaN       NaN        NaN\n",
       "1 2002-01-05 00:00:00+00:00  2.0         2.2       2.1        4.0\n",
       "2 2002-01-15 00:00:00+00:00  2.4         2.1       2.1        2.0\n",
       "3 2002-02-04 00:00:00+00:00  3.0         NaN       NaN        0.0\n",
       "4 2002-02-09 00:00:00+00:00  2.0         NaN       NaN        NaN"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def filter_date(df, date, delta, v_fd, d_fd):\n",
    "    df_t=df.loc[(df[d_fd]>=(date-dt.timedelta(days=delta)))&(df[d_fd]<=(date+dt.timedelta(days=delta)))]\n",
    "    return df_t[v_fd].median(skipna=True),df_t[v_fd].mean(skipna=True), df_t[v_fd].count()\n",
    "\n",
    "# df_s[['mv','md']]=\n",
    "# print(\n",
    "delta=2\n",
    "median_fd='median_d_'+str(delta)\n",
    "mean_fd='mean_d_'+str(delta)\n",
    "count_fd='count_d_'+str(delta)\n",
    "\n",
    "df_s[[median_fd,mean_fd, count_fd]]=df_sx.apply(lambda x: filter_date(df_gx,x['date'],delta,'val','date'), axis=1).apply(pd.Series)\n",
    "\n",
    "# for index, row in df_s.iterrows():\n",
    "#     print(row['date']-dt.timedelta(days=2))\n",
    "#     print(row['date']+dt.timedelta(days=2))\n",
    "#     df_t=df_g.loc[(df_g['date']>=(row['date']-dt.timedelta(days=2)))&(df_g['date']<=(row['date']+dt.timedelta(days=2)))]\n",
    "#     print(df_t, '\\n')\n",
    "#     mean_x=df_t['val'].median()\n",
    "#     print(mean_x, df_t)\n",
    "df_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
